{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = data[\"data\"], columns=data[\"feature_names\"])\n",
    "y= data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([212, 357], dtype=int64))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping = EarlyStopping(patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layers, with a good practice of the number of neurons = no.features\n",
    "# last layer is sigmoid: 0->1 \n",
    "model.add(Dense(30,activation =\"relu\"))\n",
    "model.add(Dense(15,activation =\"relu\"))\n",
    "model.add(Dense(1,activation =\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss =\"binary_crossentropy\",metrics=\"accuracy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 1s 16ms/step - loss: 0.6685 - accuracy: 0.4331 - val_loss: 0.6561 - val_accuracy: 0.5904\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.7743 - val_loss: 0.6208 - val_accuracy: 0.8617\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.8583 - val_loss: 0.5836 - val_accuracy: 0.8830\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.8688 - val_loss: 0.5449 - val_accuracy: 0.8883\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.8740 - val_loss: 0.5037 - val_accuracy: 0.8989\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.8793 - val_loss: 0.4554 - val_accuracy: 0.9096\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8871 - val_loss: 0.4001 - val_accuracy: 0.9202\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8845 - val_loss: 0.3602 - val_accuracy: 0.9255\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.9029 - val_loss: 0.3258 - val_accuracy: 0.9202\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.9239 - val_loss: 0.3006 - val_accuracy: 0.9309\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.9239 - val_loss: 0.2752 - val_accuracy: 0.9149\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.9291 - val_loss: 0.2557 - val_accuracy: 0.9202\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.9239 - val_loss: 0.2387 - val_accuracy: 0.9255\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9265 - val_loss: 0.2254 - val_accuracy: 0.9255\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9265 - val_loss: 0.2110 - val_accuracy: 0.9149\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.9318 - val_loss: 0.2019 - val_accuracy: 0.9255\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.9370 - val_loss: 0.1914 - val_accuracy: 0.9255\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9449 - val_loss: 0.1849 - val_accuracy: 0.9255\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1729 - accuracy: 0.9449 - val_loss: 0.1739 - val_accuracy: 0.9362\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.9475 - val_loss: 0.1725 - val_accuracy: 0.9255\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.9475 - val_loss: 0.1618 - val_accuracy: 0.9255\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9475 - val_loss: 0.1582 - val_accuracy: 0.9255\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9580 - val_loss: 0.1500 - val_accuracy: 0.9362\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9554 - val_loss: 0.1441 - val_accuracy: 0.9415\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9528 - val_loss: 0.1392 - val_accuracy: 0.9415\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9606 - val_loss: 0.1351 - val_accuracy: 0.9521\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9580 - val_loss: 0.1278 - val_accuracy: 0.9415\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9606 - val_loss: 0.1307 - val_accuracy: 0.9628\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9633 - val_loss: 0.1201 - val_accuracy: 0.9521\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9633 - val_loss: 0.1183 - val_accuracy: 0.9574\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9606 - val_loss: 0.1139 - val_accuracy: 0.9521\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9633 - val_loss: 0.1128 - val_accuracy: 0.9628\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9633 - val_loss: 0.1086 - val_accuracy: 0.9628\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9659 - val_loss: 0.1048 - val_accuracy: 0.9628\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9685 - val_loss: 0.1027 - val_accuracy: 0.9628\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0988 - accuracy: 0.9659 - val_loss: 0.0997 - val_accuracy: 0.9628\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9738 - val_loss: 0.0978 - val_accuracy: 0.9628\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0938 - accuracy: 0.9764 - val_loss: 0.0974 - val_accuracy: 0.9681\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9816 - val_loss: 0.0909 - val_accuracy: 0.9734\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9685 - val_loss: 0.0899 - val_accuracy: 0.9681\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9764 - val_loss: 0.0886 - val_accuracy: 0.9734\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9738 - val_loss: 0.0853 - val_accuracy: 0.9787\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9816 - val_loss: 0.0871 - val_accuracy: 0.9734\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9790 - val_loss: 0.0825 - val_accuracy: 0.9840\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9816 - val_loss: 0.0841 - val_accuracy: 0.9734\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9843 - val_loss: 0.0797 - val_accuracy: 0.9787\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9764 - val_loss: 0.0815 - val_accuracy: 0.9734\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9816 - val_loss: 0.0799 - val_accuracy: 0.9734\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9790 - val_loss: 0.0756 - val_accuracy: 0.9840\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9895 - val_loss: 0.0759 - val_accuracy: 0.9787\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9790 - val_loss: 0.0731 - val_accuracy: 0.9840\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9843 - val_loss: 0.0798 - val_accuracy: 0.9681\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9843 - val_loss: 0.0719 - val_accuracy: 0.9840\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9843 - val_loss: 0.0742 - val_accuracy: 0.9734\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9843 - val_loss: 0.0717 - val_accuracy: 0.9787\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9869 - val_loss: 0.0691 - val_accuracy: 0.9840\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9869 - val_loss: 0.0682 - val_accuracy: 0.9840\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9869 - val_loss: 0.0671 - val_accuracy: 0.9840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9843 - val_loss: 0.0695 - val_accuracy: 0.9787\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9816 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9843 - val_loss: 0.0655 - val_accuracy: 0.9787\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9869 - val_loss: 0.0643 - val_accuracy: 0.9840\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9895 - val_loss: 0.0674 - val_accuracy: 0.9787\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9869 - val_loss: 0.0623 - val_accuracy: 0.9840\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.9869 - val_loss: 0.0640 - val_accuracy: 0.9787\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9869 - val_loss: 0.0636 - val_accuracy: 0.9787\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9869 - val_loss: 0.0635 - val_accuracy: 0.9787\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.0607 - val_accuracy: 0.9840\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9895 - val_loss: 0.0640 - val_accuracy: 0.9734\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9921 - val_loss: 0.0585 - val_accuracy: 0.9840\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9869 - val_loss: 0.0609 - val_accuracy: 0.9787\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9921 - val_loss: 0.0587 - val_accuracy: 0.9840\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9869 - val_loss: 0.0592 - val_accuracy: 0.9787\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9869 - val_loss: 0.0581 - val_accuracy: 0.9787\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9869 - val_loss: 0.0596 - val_accuracy: 0.9787\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9895 - val_loss: 0.0573 - val_accuracy: 0.9787\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9895 - val_loss: 0.0591 - val_accuracy: 0.9787\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9869 - val_loss: 0.0552 - val_accuracy: 0.9840\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9895 - val_loss: 0.0596 - val_accuracy: 0.9787\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9895 - val_loss: 0.0548 - val_accuracy: 0.9840\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9869 - val_loss: 0.0551 - val_accuracy: 0.9840\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9843 - val_loss: 0.0606 - val_accuracy: 0.9787\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9895 - val_loss: 0.0540 - val_accuracy: 0.9894\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9921 - val_loss: 0.0581 - val_accuracy: 0.9787\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9869 - val_loss: 0.0540 - val_accuracy: 0.9787\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9869 - val_loss: 0.0548 - val_accuracy: 0.9787\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9869 - val_loss: 0.0555 - val_accuracy: 0.9840\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9895 - val_loss: 0.0556 - val_accuracy: 0.9840\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9895 - val_loss: 0.0534 - val_accuracy: 0.9840\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9895 - val_loss: 0.0551 - val_accuracy: 0.9787\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9869 - val_loss: 0.0511 - val_accuracy: 0.9840\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9895 - val_loss: 0.0520 - val_accuracy: 0.9840\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9895 - val_loss: 0.0514 - val_accuracy: 0.9787\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9895 - val_loss: 0.0534 - val_accuracy: 0.9840\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9869 - val_loss: 0.0526 - val_accuracy: 0.9840\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9921 - val_loss: 0.0515 - val_accuracy: 0.9840\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9921 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9895 - val_loss: 0.0518 - val_accuracy: 0.9840\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9921 - val_loss: 0.0502 - val_accuracy: 0.9840\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9869 - val_loss: 0.0500 - val_accuracy: 0.9840\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9869 - val_loss: 0.0518 - val_accuracy: 0.9840\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9921 - val_loss: 0.0498 - val_accuracy: 0.9840\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9921 - val_loss: 0.0496 - val_accuracy: 0.9840\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.0546 - val_accuracy: 0.9787\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.0494 - val_accuracy: 0.9894\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9869 - val_loss: 0.0518 - val_accuracy: 0.9787\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9921 - val_loss: 0.0487 - val_accuracy: 0.9894\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9895 - val_loss: 0.0508 - val_accuracy: 0.9840\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9895 - val_loss: 0.0507 - val_accuracy: 0.9840\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9895 - val_loss: 0.0508 - val_accuracy: 0.9840\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9921 - val_loss: 0.0483 - val_accuracy: 0.9894\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9895 - val_loss: 0.0486 - val_accuracy: 0.9894\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9787\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9869 - val_loss: 0.0465 - val_accuracy: 0.9947\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9869 - val_loss: 0.0502 - val_accuracy: 0.9840\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9921 - val_loss: 0.0461 - val_accuracy: 0.9947\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9921 - val_loss: 0.0511 - val_accuracy: 0.9787\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9895 - val_loss: 0.0512 - val_accuracy: 0.9787\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.0461 - val_accuracy: 0.9894\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9921 - val_loss: 0.0559 - val_accuracy: 0.9787\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9869 - val_loss: 0.0453 - val_accuracy: 0.9947\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9895 - val_loss: 0.0563 - val_accuracy: 0.9787\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9895 - val_loss: 0.0468 - val_accuracy: 0.9894\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9921 - val_loss: 0.0490 - val_accuracy: 0.9894\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9921 - val_loss: 0.0470 - val_accuracy: 0.9894\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9921 - val_loss: 0.0498 - val_accuracy: 0.9840\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9921 - val_loss: 0.0475 - val_accuracy: 0.9894\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 0.0464 - val_accuracy: 0.9894\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9869 - val_loss: 0.0529 - val_accuracy: 0.9787\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.0558 - val_accuracy: 0.9787\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 0.0459 - val_accuracy: 0.9947\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9921 - val_loss: 0.0483 - val_accuracy: 0.9894\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9921 - val_loss: 0.0497 - val_accuracy: 0.9840\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 0.0468 - val_accuracy: 0.9894\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9921 - val_loss: 0.0461 - val_accuracy: 0.9894\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0538 - val_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1727fa739d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,callbacks= stopping, epochs= 500,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05381398648023605, 0.978723406791687]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLEARN - MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sk = MLPClassifier(hidden_layer_sizes=30,activation=\"relu\",solver=\"adam\",max_iter=500,early_stopping=True,n_iter_no_change=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=30, max_iter=500,\n",
       "              n_iter_no_change=15)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sk.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8974358974358975"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sk.best_validation_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sk.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9308510638297872"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sk.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
